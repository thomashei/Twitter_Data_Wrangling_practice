{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Report\n",
    "\n",
    "## Introduction\n",
    "In this paper I am going to describe the wrangling process I have made in this project to get necessary, clean and tidy data on hand for doing analysis. Data wrangling include three steps:\n",
    "\n",
    "1. Gathering data\n",
    "2. Accessing Data\n",
    "3. Cleaning Data\n",
    "\n",
    "These steps will be described explained with point form as below.\n",
    "\n",
    "## 1. Gathering data\n",
    "\n",
    "In order to doing data analysis for WeRateDogs, we need 3 sets of data. The are collected in different ways.\n",
    "\n",
    "- The first file we need is WeRateDogs Twitter archive. This is simpliest one. Just download the csv file manually by clicking the following link: [twitter-archive-enhanced.csv](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv). The file is read and loaded as dataframe named \"twitter_archive\".\n",
    "\n",
    "\n",
    "- The second file we need is Image predictions. We download the tsv file programmatically. By using Python Requests library, we are able to access the file from Udacity's servers with the provided [URL](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv) and save it through Python open and write function.\n",
    "\n",
    "\n",
    "- The last file we need is the Tweet data of WeRateDogs. To get these data, firstly I need to apply for a Twitter API account. After the application is approved, I got the key and token which are essential for using the Python library Tweepy.Download tweet data through Tweepy by referencing the tweet ID list which can be found in Twitter archive. Write the data we download in JSON file then read the JSON file in Python dataframe. There are few columns in the dataset but we only need retweet count and favorite count for further analysis. Finally save is as csv file to workspace for easy opening every time.\n",
    "\n",
    "\n",
    "We are now having all the dataset we need. In variable they are twitter_archive, image_prediction and tweet_api.\n",
    "\n",
    "## 2. Accessing data\n",
    "\n",
    "After gathering all the above data, access them and find out the issues visually and programmatically which we are going to fix them in the next part. The issues can be grouped in two categories - quality issues and tidiness issues. All of them are summarized as below after investigation.\n",
    "\n",
    "### Quality issues\n",
    "\n",
    "Twitter archive:\n",
    "\n",
    "- timestamp should be datetime instead of object\n",
    "- tweet_id should be string instead of int\n",
    "- Reply and retweet id data type should be string instead of float\n",
    "- rating numerator should be float instead of int as contains demical value\n",
    "- The numerator and denominator columns have invalid values\n",
    "- Find invalid names like \"get\", \"a\" in the name column\n",
    "- Guess the name \"None\" means null value, should change to programmable null value\n",
    "- text column contains url. Should be in different column.\n",
    "- source column come with the opening and closing tag\n",
    "- retweets and some replys are not needed\n",
    "- Some columns are not necessary for data analysis\n",
    "\n",
    "Image prediction:\n",
    "\n",
    "- data of breed of dog sometimes in capital letter\n",
    "- Tweet id should be str instead of int\n",
    "- Don't need to have all three level of image-prediction\n",
    "\n",
    "Twitter API:\n",
    "\n",
    "- Tweet id should be str instead of int\n",
    "\n",
    "### Tidiness issues\n",
    "\n",
    "Twitter archive:\n",
    "\n",
    "- Stages of dog can be combined into one coulmn\n",
    "- If we extract the URL from text column, which will be duplicate with the expanded_urls column\n",
    "\n",
    "Overall:\n",
    "\n",
    "- Basically we can combine all tables in one\n",
    "\n",
    "\n",
    "\n",
    "## 3. Cleaning data\n",
    "\n",
    "I start cleaning and fix the problems I found in part two. First of all, copy all three sets of data, one for cleaing and the other for comparison. Every issues are fixed by following the define-code-test flow.\n",
    "\n",
    "### Quality issues\n",
    "\n",
    "1. Fix the incorrect data type by using astype function\n",
    "    - timestamp, retweeted_status_timestamp to datetime format\n",
    "    - tweet_id to string\n",
    "    - rating_numerator to float\n",
    "    - in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id to string\n",
    "\n",
    "\n",
    "2. Fix numerator and denominator which contain invalid value\n",
    "    - found that the numbers of numerator and denominator are extracted from the first \"n/n\" in the text\n",
    "    - denominator which is not equal to 10, and numerator which is larger than 15, are considered as invalid rating\n",
    "    - find the valid rating by grabing the number from the tail of the text\n",
    "    - extract the last number in the text as denominator and second last number as numerator\n",
    "    - multiple dog in one picture were given a large number of rating\n",
    "    - get the number of dogs in each picture and divide the numerator with that number\n",
    "    - finally replace the multipled denominator with a standard \"10\"\n",
    "\n",
    "\n",
    "3. Fix invalid dog name\n",
    "    - Python extracted wrong words from the text and they become dog name \n",
    "    - suppose the names with lowercase first letter are all invalid name and change them all to NaN\n",
    "    - \"None\" means NaN as well, so replace them all with NaN\n",
    "\n",
    "\n",
    "4. Remove URL from text column\n",
    "    - use regex to find out the URL from text and create anew column to store them\n",
    "    - remove the URL from text column by replace function\n",
    "  \n",
    "  \n",
    "5. Remove opening and closing tag from source column\n",
    "    - removing the tag is actually equal to extracting the text in between \">\" and \"<\"\n",
    "\n",
    "\n",
    "6. Change breed of dog into lowercase letter\n",
    "    - values in breed_prediction column are not standardize, some with capital letter and some are not\n",
    "    - change all values in breed_prediction column into small letters\n",
    " \n",
    " \n",
    "7. Make image prediction anc confidence level columns into one respectively\n",
    "    - keep only the first value which predicted the picture as dog and its level of confidence\n",
    "    - if all three prediction are not dog, show NaN\n",
    " \n",
    " \n",
    "8. Drop tweets which is retweet and some reply\n",
    "    - Remove all rows that have values in retweeted_status_id, retweeted_status_user_id, and retweeted_status_timestamp columns\n",
    "    - Only keep the replies that contain dog rating, which means only the replies made by WeRateDogs (ID:4196983835)\n",
    "    \n",
    "    \n",
    "9. Drop unnecessary columns and fix other minor issues during final check\n",
    "    - drop columns which are not need for analysis in next part\n",
    "    - replace all the 0 in favorite_count to NaN value\n",
    "    - find out the tweets which are rated higher than 14 and drop them\n",
    "    - some NaN are actually string, change them to NaN value\n",
    "\n",
    "\n",
    "### Tidiness issues\n",
    "\n",
    "1. Stage of dog can be in one column\n",
    "    - create a dog_stage column by melting the 4 original stages\n",
    "    - tweet ID repeat four times after melting because there are 4 stages, we just need to keep the non-NaN value\n",
    "    - Some tweets contain two or more different dog stages\n",
    "    - join two stages in one cell, otherwise there are dulpicate tweet ID \n",
    "\n",
    "\n",
    "2. Combine all three tabels as one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
